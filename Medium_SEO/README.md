The scraper requires the user to log in to medium.com before being used

The dataset contains data from 700+ medium.com top articles under the "Data Science' tag.

the below are the columns in the dataset for analysis:

- article_url	: url to the scraped article
- best_of	: indicated the catagory from which the article was scraped (best of "All time", "This year, "This week", "Trending"
- title : article title	
- summary	: the whole body of the article
- image_count	: number or images used within the body of article (ad images  and images of related articles were not counted)
- link_count	: number of links within the body of the article
- blockquote_count	: number of quote blocks used
- publication_date	: when the article was published
- reading_time	: reading time in minutes
- clap_count : total number of claps for the article
- unique_clap_count	: total number of unique people who gave claps to the article
- comment_count	: ntotal number of comments
- author_url	: url to the author's medium page
- author_name	: author's name
- publication_url	: url where the article was published on (left blank if published independently)
- publication_name	: name of the publication the article was published on
- codeblock_count	: total number of codeblocks used
- code_count	: total lines of codes present within the body of the article
- all_codes_list  : a list containg all the lines of codes present within	the article (can be used for further data cleaning)																																																																																																																																																																																																																																													

